{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Download\n",
    "\n",
    "This Dataset was provided by the \"Dust and Data\" project.\n",
    "\n",
    "In this Notebook the dataset will be downloaded into a folder. Further Processing will then be handled in a seperate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import urllib.request\n",
    "from time import sleep\n",
    "import logging\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "database_file = os.path.join(os.getcwd(), 'xmlkultur.xlsx')\n",
    "assert os.path.exists(database_file), 'The Dataset is not in the expected directory'\n",
    "\n",
    "target_dir = os.path.join(os.getcwd(), 'images')\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "\n",
    "df = pd.read_excel(database_file, index_col=0)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking assumptions\n",
    "In order to be sure that there are no images in this dataset that do not fall under the expected license or publisher, I quickly check the three correlated columns.\n",
    "\n",
    "I also check if I have to handle multiple fileformats and wheter the filenames I am planning on using are actually unique identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rights = df['Rights'].unique()\n",
    "ds_license = df['CreativeCommons'].unique()\n",
    "publisher = df['Publisher'].unique()\n",
    "file_formats = df['Format'].unique()\n",
    "\n",
    "assert len(rights) == 1 and len(ds_license) == 1 and len(publisher) == 1 and \\\n",
    "       rights[0] == 'Österreichische Galerie Belvedere' and \\\n",
    "       ds_license[0] == 'https://creativecommons.org/licenses/by-sa/4.0/' and \\\n",
    "       publisher[0] == 'Österreichische Galerie Belvedere', 'UNEXPECTED LEGAL STATUS'\n",
    "print('Legal status is as expected.')\n",
    "\n",
    "assert len(file_formats) == 1 and file_formats[0] == 'image/jpeg', 'Unsuspected file format'\n",
    "print('File formats are as expected.')\n",
    "\n",
    "assert len(df['Identifier'].unique()) == df.shape[0], 'Object Id is not a unique identifier'\n",
    "print('Naming scheme is as expected.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the images are provided as jpeg files, I save them as pngs, as I do not know how I will deal with the images later on in the project and jpeg files can quickly degrade if modified and saved frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the images\n",
    "Since I do not want to risk overloading the servers by sending thousands of requests at once, a delay between each download is introduced. This slows down the process significantly, but it is important in order to prevent an unintented Denial of Service attack.\n",
    "Since there does not seem to be a robots.txt file for sammlung.belvedere.at, I use a delay of 10 seconds per request, which has the effect that I barely put any load on the server whatsoever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = os.path.join(os.getcwd(), 'download_errors.log')\n",
    "logger = logging.getLogger('failed_download')\n",
    "logger.addHandler(logging.FileHandler(log_file))\n",
    "\n",
    "failed_downloads = []\n",
    "with open(log_file) as f:\n",
    "    for line in f.readlines():\n",
    "        failed_downloads.append(line.rstrip())\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    obj_name_jpg = row['Identifier'] + '.jpg'\n",
    "    obj_name_png = row['Identifier'] + '.png'\n",
    "\n",
    "    # Do not request images, that were already downloaded or failed before\n",
    "    if row['Identifier'] in failed_downloads or os.path.exists(os.path.join(target_dir, obj_name_png)):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        urllib.request.urlretrieve(row['Object'], os.path.join(target_dir, obj_name_jpg))\n",
    "        sleep(10)\n",
    "    except:\n",
    "        logger.error(f'{row[\"Identifier\"]}')\n",
    "        sleep(10)\n",
    "        continue\n",
    "\n",
    "    # Converting to png\n",
    "    im = Image.open(os.path.join(target_dir, obj_name_jpg))\n",
    "    im.save(os.path.join(target_dir, obj_name_png))\n",
    "    os.remove(os.path.join(target_dir, obj_name_jpg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the download\n",
    "Checking if an attempt for downloading was made for every image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Failed download set is reloaded to account for the errors of the last cell\n",
    "failed_downloads = []\n",
    "with open(log_file) as f:\n",
    "    [failed_downloads.append(line.rstrip()) for line in f.readlines()]\n",
    "\n",
    "for f in os.listdir(target_dir):\n",
    "    assert os.path.isfile(os.path.join(target_dir, f)) or not f.endswith('.png'), 'Unexpected finding (either folder or file that is not a png): {f}'\n",
    "    assert (df['Identifier'] == f[:-4]).any(), f'No matching identifier was found in the dataset for the picture {f}'\n",
    "\n",
    "successful_downloads = len([png for png in os.listdir(target_dir)])\n",
    "\n",
    "accounted_for = len(set(failed_downloads)) + successful_downloads\n",
    "\n",
    "assert accounted_for == df.shape[0], f'Missmatch: {df.shape[0]} expected, but found {successful_downloads + len(failed_downloads)}: {successful_downloads} successfully downloaded and {len(set(failed_downloads))} accounted for as failed'\n",
    "print(f'{len(failed_downloads)} images are counted as missing. Not considering these, the dataset is complete. If there are missing images, they are referenced in the log file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing images\n",
    "For the following identifiers the images are still missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*set(failed_downloads), sep=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Masters-Thesis-Implementation)",
   "language": "python",
   "name": "pycharm-8f91eb99"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
